[
  {
    "slug": "turning-digital-dust-into-consulting-platform",
    "title": "Turning Digital Dust into a Consulting Platform: The Rebuild of MADE, Inc.",
    "date": "2025-09-16",
    "author": "Brian Fending",
    "excerpt": "After six years away from consulting, I transformed a dormant WordPress site into an AI-powered assessment platform that demonstrates methodology through action, showing how AI-assisted development enables solo developers to build sophisticated consulting platforms.",
    "content": "Most consulting websites describe what you can do without demonstrating how you think and execute. After six years, I found MADE, Inc. sitting as abandoned WordPress brochureware. The rebuild transformed it into an AI-powered assessment platform that makes prospects experience methodology before ever talking to me.\n\nThe platform features four assessment tracks addressing consistent organizational struggles: AI Risk Assessment revealing the 3-5x hidden AI applications companies don't realize they're running, Product Development Maturity distinguishing between having a process and having a scaling process, Technology Governance separating theater from enablement, and Security Posture assessing pattern anticipation beyond checklists. Each assessment uses questions based on respected research, evolving from surface-level checkboxes to reveal actual business problems and organizational maturity patterns.\n\nAI processes assessment data with extensive context about what scores mean in practice, generating nuanced insights about organizational dynamics that procedural logic couldn't capture. The platform stores and versions every summary tied to specific assessments, enabling historical consistency while allowing methodology evolution. This creates a foundation for proprietary market research as data accrues over time.",
    "tags": [
      "AI development",
      "consulting",
      "platform engineering",
      "Next.js",
      "WordPress migration",
      "assessment platforms",
      "Claude Code",
      "business transformation"
    ],
    "featuredImage": "madeinc_licensed_artwork_pixelated.png",
    "metaDescription": "Learn how I rebuilt MADE, Inc. from abandoned WordPress to AI-powered assessment platform using Claude Code, Next.js, and modern development practices. A case study in demonstrating consulting expertise through technology.",
    "linkedinUrl": "https://www.linkedin.com/pulse/turning-digital-dust-consulting-platform-rebuild-made-brian-fending-euafe",
    "substackUrl": "https://brianfending.substack.com/p/turning-digital-dust-into-a-consulting"
  },
  {
    "slug": "implementing-nist-ai-rmf-managing-part-4-4",
    "title": "Implementing NIST AI RMF: Managing (Part 4 of 4)",
    "date": "2025-08-02",
    "author": "Brian Fending",
    "excerpt": "Operationalizing governance at scale: moving from pilot purgatory to production deployment while maintaining control. Part 4 transforms NIST frameworks into sustainable operations that deliver consistent business value without collapsing under operational complexity.",
    "content": "Most organizations get stuck between successful AI pilots and production deployment. Governance frameworks that work perfectly for a few pilot projects collapse under the operational complexity of managing dozens of AI systems in production. Teams build comprehensive frameworks but discover their approaches require manual oversight that doesn't scale.\n\nThe NIST AI RMF MANAGE function addresses this through four operational capabilities: risk prioritization integrated with existing systems, benefit maximization strategies focused on business outcomes, systematic third-party vendor management, and continuous monitoring with automated exception handling.\n\nTraditional checklist governance proves insufficient for emerging complexity like multi-agent systems and Model Context Protocol architectures. These create new blind spots through cascading hallucinations and autonomous behaviors that conflict with human oversight requirements. Organizations need \"AgentOps\" approaches that monitor agent behavior and maintain accountability across distributed AI systems.",
    "tags": [
      "NIST",
      "AI governance",
      "operational scale",
      "AI RMF",
      "vendor management",
      "enterprise AI",
      "risk management"
    ],
    "featuredImage": "NIST_AI_RMF_4_manage.png",
    "metaDescription": "Operationalizing governance at scale: moving from pilot purgatory to production deployment while maintaining control. Part 4 transforms NIST frameworks into sustainable operations that deliver consistent business value without collapsing under operational complexity.",
    "linkedinUrl": "https://www.linkedin.com/pulse/implementing-nist-ai-rmf-managing-part-4-brian-fending-hvexe",
    "substackUrl": "https://brianfending.substack.com/p/implementing-nist-ai-rmf-managing"
  },
  {
    "slug": "implementing-nist-ai-rmf-measuring-part-3-4",
    "title": "Implementing NIST AI RMF: Measuring (Part 3 of 4)",
    "date": "2025-07-25",
    "author": "Brian Fending",
    "excerpt": "Beyond trust theater: implementing metrics that actually matter for AI trustworthiness. Part 3 transforms measurement from technical performance dashboards to systematic evaluation of the seven NIST characteristics that determine whether AI systems are safe to deploy.",
    "content": "Most AI measurement systems focus on technical performance while missing basic safety and fairness evaluations. While 75% of AI initiatives fail, organizations continue reporting success based on narrow performance metrics alone, like tracking uptime while ignoring response quality.\n\nAI systems require evaluation across seven NIST trustworthiness characteristics that traditional metrics miss completely: validity, safety, security, accountability, explainability, privacy enhancement, and fairness. Organizations that evaluate trustworthiness before deployment avoid the drift and inconsistencies that destroy user trust.\n\nThe NIST AI RMF MEASURE function transforms measurement from performance theater into systematic trustworthiness evaluation. Instead of beautiful dashboards showing perfect technical metrics, organizations build frameworks that assess whether AI systems actually work safely in production.\n\nThis is Part 3 of the four-part NIST AI RMF implementation series. The part where you stop relying on convenience metrics, and start measuring trust (and trustworthiness!) before your AI systems fail in ways that matter.",
    "tags": [
      "NIST",
      "AI measurement",
      "trustworthiness metrics",
      "AI RMF",
      "AI evaluation",
      "enterprise AI",
      "risk management"
    ],
    "featuredImage": "NIST_AI_RMF_3_measure.png",
    "metaDescription": "Beyond trust theater: implementing metrics that actually matter for AI trustworthiness. Part 3 transforms measurement from technical performance dashboards to systematic evaluation of the seven NIST characteristics that determine whether AI systems are safe to deploy.",
    "linkedinUrl": "https://www.linkedin.com/pulse/implementing-nist-ai-rmf-measuring-part-3-4-brian-fending-1iige",
    "substackUrl": "https://brianfending.substack.com/p/implementing-nist-ai-rmf-measuring"
  },
  {
    "slug": "implementing-nist-ai-rmf-mapping-part-2-4",
    "title": "Implementing NIST AI RMF: Mapping (Part 2 of 4)",
    "date": "2025-06-30",
    "author": "Brian Fending",
    "excerpt": "The real AI governance crisis isn't the models you've formally approved, it's the ones you don't know exist. Part 2 tackles the visibility gap that's creating compliance exposure and security risks.",
    "content": "The real AI governance crisis isn't the models you've formally approved, it's the ones you don't know exist. Organizations consistently underestimate their AI footprint by 3-5x when conducting systematic inventories, creating immediate compliance exposure and security risks.\n\nTraditional IT asset management fails catastrophically for AI because vendors don't clearly disclose AI features. What gets sold as \"enhanced analytics\" or \"intelligent automation\" often includes machine learning models processing your data in ways that weren't part of the original contract review.\n\nShadow AI adoption compounds the problem. Marketing subscribes to AI writing platforms, sales deploys conversation intelligence software, finance adopts AI-powered forecasting tools, all without formal approval processes. Meanwhile, vendor updates quietly add AI functionality to existing systems.\n\nThe NIST MAP function transforms this chaos into strategic visibility through systematic discovery, categorization, and impact assessment. Organizations move from compliance theater to actionable intelligence about their actual AI landscape.\n\nThis is Part 2 of the four-part NIST AI RMF implementation series. Stop discovering AI applications during compliance audits. Start discovering them before they become problems.",
    "tags": [
      "NIST",
      "AI mapping",
      "AI discovery",
      "risk management",
      "AI RMF",
      "enterprise AI",
      "AI inventory"
    ],
    "featuredImage": "NIST_AI_RMF_2_map.png",
    "metaDescription": "The real AI governance crisis isn't the models you've formally approved, it's the ones you don't know exist. Part 2 tackles the visibility gap that's creating compliance exposure and security risks.",
    "linkedinUrl": "https://www.linkedin.com/pulse/implementing-nist-ai-rmf-mapping-part-2-4-brian-fending-dlt4e/",
    "substackUrl": "https://brianfending.substack.com/p/implementing-nist-ai-rmf-mapping"
  },
  {
    "slug": "implementing-nist-ai-rmf-governing-part-1-4",
    "title": "Implementing NIST AI RMF: Governing (Part 1 of 4)",
    "date": "2025-06-24",
    "author": "Brian Fending",
    "excerpt": "Transforming the NIST AI Risk Management Framework from compliance theater to strategic enablement. Part 1 focuses on governance structures that accelerate AI adoption while managing real risks.",
    "content": "Most AI initiatives fail because of governance problems, not technology problems. While 75% of AI projects don't deliver expected ROI, organizations keep burning budgets on \"governance theater\", or elaborate processes that miss the actual risks killing their projects.\n\nTraditional IT governance frameworks almost completely fail when it comes to AI. Your standard security reviews can't totally handle AI systems that need access to data sets no regular application would touch. Meanwhile, every software vendor is slapping AI features into their products without clear documentation or, sometimes, notice.\n\nThe NIST AI Risk Management Framework offers the first practical approach designed specifically for AI's unique challenges. Unlike compliance-heavy alternatives, it builds on existing structures and focuses on business enablement over process documentation.\n\nThis is Part 1 of a four-part series transforming NIST's framework into actionable implementation strategies. We'll cover how to build governance that accelerates AI adoption while managing real risks—moving from pilot purgatory to production value.",
    "tags": [
      "NIST",
      "AI governance",
      "risk management",
      "AI RMF",
      "compliance",
      "enterprise AI"
    ],
    "featuredImage": "NIST_AI_RMF_1_govern.png",
    "metaDescription": "Transforming the NIST AI Risk Management Framework from compliance theater to strategic enablement. Part 1 focuses on governance structures that accelerate AI adoption while managing real risks.",
    "linkedinUrl": "https://www.linkedin.com/pulse/implementing-nist-ai-rmf-governing-part-1-4-brian-fending-3wxse/",
    "substackUrl": "https://brianfending.substack.com/p/implementing-nist-ai-rmf-governing"
  },
  {
    "slug": "rethinking-team-topologies-ai-augmented-development",
    "title": "Rethinking Team Topologies for AI-Augmented Development",
    "date": "2025-06-17",
    "author": "Brian Fending",
    "excerpt": "Exploring how AI integration is reshaping software development team structures and the evolution from traditional PRD workflows to AI-augmented collaboration patterns.",
    "content": "Software development team structures are undergoing their most significant transformation since the advent of agile methodologies. When a single developer with AI assistance can produce what previously required an entire squad, traditional team topologies need fundamental rethinking.\n\nTwo distinct approaches to AI-augmented development are emerging: a single file approach that centralizes all context in one discoverable location that plays nice with autonomous AI agents, and the context directory approach that distributes knowledge across specialized documents. Each serves different organizational needs and project complexities.\n\nBut the real revolution isn't just about organizing documentation, it's about breaking down the traditional \"PRD wall\" between Product Vision and development implementation. Both approaches enable something unprecedented: embedding Product Vision directly into development context, allowing AI agents and developers to validate against original user needs rather than translated requirements. The choice between approaches depends on whether you're optimizing for immediate AI effectiveness or long-term organizational sophistication. The most successful teams are finding hybrid strategies that serve both autonomous AI agents and complex human collaboration needs.\n\nUnderstanding these emerging patterns will help you to better position your organization for the fundamental shift in how Product Vision flows through development teams.",
    "tags": [
      "team topologies",
      "AI",
      "software development",
      "organizational design",
      "DevOps"
    ],
    "featuredImage": "rethinking-team-topologies-ai-augmented-development.png",
    "metaDescription": "Exploring how AI integration is reshaping software development team structures and the evolution from traditional PRD workflows to AI-augmented collaboration patterns.",
    "linkedinUrl": "https://www.linkedin.com/pulse/rethinking-team-topologies-ai-augmented-development-brian-fending-teuke",
    "substackUrl": "https://brianfending.substack.com/p/rethinking-team-topologies-for-ai"
  },
  {
    "slug": "governance-gap-top-down-risk-management",
    "title": "The Governance Gap: Why Top-Down Risk Management is Critical",
    "date": "2025-06-06",
    "author": "Brian Fending",
    "excerpt": "McKinsey's latest research reveals a striking gap between GRC aspiration and implementation reality, further making the case for top-down approaches to risk management.",
    "content": "The digital transformation acceleration we've witnessed since 2022 has amplified the need for robust governance, risk, and compliance capabilities. Yet McKinsey's latest research reveals a substantial gap between GRC aspiration and implementation reality.\n\nMcKinsey's 2025 Global GRC Benchmarking Survey found that \"excellent governance, risk, and compliance (GRC) is a common aspiration, but how often is it a reality? For most companies, GRC is a work in progress.\" Despite 93% of organizations having framework documents, implementation gaps are enormous—nearly half lack formal governance procedures.\n\nThe survey reveals a striking correlation: organizations where the head of risk is positioned more than one level below the CEO report significantly less mature risk functions. This validates what ISACA has long advocated—that top-down approaches yield better results than bottom-up initiatives.\n\nPerhaps most concerning is the resource reality: 66% of companies operate risk management with just 20 or fewer full-time staff. When resources are this constrained, organizations can't afford ineffective approaches.\n\nThis is precisely why I developed the Matrix Approach to incremental DRP and BCP review—a multi-dimensional framework that addresses the exact challenges identified in McKinsey's research through classification systems, incremental review cadences, and progressive live drills.\n\nSo we don't really have a framework problem, we have an adoption problem. The research is clear: pragmatic-to-a-fault bottom-up approaches fail to deliver needed maturity. It's time to embrace top-down, matrix-based frameworks that connect executive priorities to operational activities.",
    "tags": [
      "risk management",
      "GRC",
      "governance",
      "compliance",
      "enterprise security"
    ],
    "featuredImage": "grc_topdown_article_art_2025-06-06_vignette.png",
    "metaDescription": "McKinsey's latest research reveals a striking gap between GRC aspiration and implementation reality, further making the case for top-down approaches to risk management.",
    "linkedinUrl": "https://www.linkedin.com/pulse/governance-gap-why-top-down-risk-management-critical-brian-fending-c2imc/",
    "substackUrl": "https://brianfending.substack.com/p/the-governance-gap-why-top-down-risk"
  },
  {
    "slug": "matrix-approach-incremental-drp-bcp-review",
    "title": "The Matrix Approach to Incremental DRP and BCP Review",
    "date": "2025-05-24",
    "author": "Brian Fending",
    "excerpt": "A multi-dimensional framework for maintaining disaster recovery and business continuity plans through incremental reviews, addressing the gap between documentation and actual recovery capabilities.",
    "content": "The technology landscape changes faster than ever, yet many organizations treat disaster recovery and business continuity planning as periodic \"check-the-box\" exercises rather than living documents. This creates a dangerous gap between documented plans and actual recovery capabilities.\n\nTraditional approaches suffer from annual review syndrome, documentation without testing, siloed planning, and outdated assumptions. The Matrix Approach offers a multi-dimensional framework that classifies every recovery component across three dimensions: System Tiers (0-3 based on criticality), Process Categories (A-D based on business impact), and Personnel Functions (Essential through Deferred).\n\nEach cell in the matrix gets its own review cadence, validation method, and ownership assignment. Monthly reviews focus on Tier 0 systems, quarterly reviews cover Tier 1 systems and Category A processes, while semi-annual and annual reviews encompass broader system validation.\n\nKey innovations include recovery component heat mapping, trigger-based reviews responding to organizational changes, composite recovery teams organized by capability rather than department, and clear component dependency mapping. Breaking monolithic plans into sub-plans with dedicated ownership ensures effective maintenance.\n\nCompared to traditional ISACA/COBIT approaches, the Matrix Approach provides better integration through its multi-dimensional view, distributes testing burden throughout the year, and creates a dynamic management system that responds to organizational changes.",
    "tags": [
      "disaster recovery",
      "business continuity",
      "risk management",
      "framework",
      "matrix approach"
    ],
    "featuredImage": "matrix-approach-drp-bcp.png",
    "metaDescription": "A multi-dimensional framework for maintaining disaster recovery and business continuity plans through incremental reviews, addressing the gap between documentation and actual recovery capabilities.",
    "linkedinUrl": "https://www.linkedin.com/pulse/matrix-approach-incremental-drp-bcp-review-brian-fending-3klie/",
    "substackUrl": "https://brianfending.substack.com/p/the-matrix-approach-to-incremental"
  },
  {
    "slug": "risk-management-ai",
    "title": "A Risk Management Analysis of Google's A2A and Anthropic's MCP",
    "date": "2025-04-10",
    "author": "Brian Fending",
    "excerpt": "Examining how traditional risk frameworks apply to emerging AI technologies, with a focus on agent-to-agent communication systems and multi-context planning.",
    "content": "Have you noticed it's been hard to keep pace with AI news lately? In this article, \nI examine how traditional risk frameworks apply to emerging AI technologies, with a particular \nfocus on Google's Agent-to-Agent (A2A) communication and Anthropic's Multi-Context Planning (MCP).\n\nThis piece explores:\n\n- The n^a potential workflows created by Agent-to-Agent communication\n- How traditional GRC frameworks fall short with modern AI implementations\n- Three practical risk mitigation strategies for enterprise AI deployment\n\nIf you're responsible for technology risk management in your organization, this analysis \nprovides a practical framework for approaching AI integration with appropriate safeguards.\n\nAs AI systems become more autonomous and capable of communicating with each other, the \ncomplexity of potential interactions grows exponentially. Enterprise risk teams need to \ndevelop new approaches to manage these interactions, particularly in regulated industries.\n\nTraditional governance, risk, and compliance (GRC) frameworks were designed for human-to-human \nand human-to-machine interactions. They struggle to account for complex machine-to-machine \ninteractions, especially when those machines possess adaptive learning capabilities.\n\nRead the full article to learn about specific frameworks and approaches that work \nin today's rapidly evolving AI landscape.",
    "tags": [
      "AI",
      "risk management",
      "technology"
    ],
    "featuredImage": "a2a_mcp_image.png",
    "metaDescription": "Examining how traditional risk frameworks apply to emerging AI technologies, with a focus on agent-to-agent communication systems and multi-context planning.",
    "linkedinUrl": "https://www.linkedin.com/pulse/risk-management-analysis-googles-a2a-anthropics-mcp-brian-fending-9yjhe/",
    "substackUrl": "https://brianfending.substack.com/p/a-risk-management-analysis-of-googles"
  }
]